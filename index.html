<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.4.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="代码块工作室">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="代码块工作室">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="代码块工作室">






  <link rel="canonical" href="http://yoursite.com/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>代码块工作室</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">代码块工作室</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />Categories</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/20/2.hdfs-shell操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="严亮">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="代码块工作室">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/20/2.hdfs-shell操作/" itemprop="url">
                  2.hdfs-shell操作.md
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-09-20 10:18:32 / Modified: 11:56:31" itemprop="dateCreated datePublished" datetime="2018-09-20T10:18:32+08:00">2018-09-20</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/大数据/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h3 id="1-hdfs命令行客户端"><a href="#1-hdfs命令行客户端" class="headerlink" title="1.hdfs命令行客户端"></a>1.hdfs命令行客户端</h3><p>HDFS提供shell命令行客户端，使用方法如下：</p>
<p>可以使用一下两种形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs   -…  &lt;args&gt;</span><br><span class="line">hdfs dfs    -…  &lt;args&gt;</span><br></pre></td></tr></table></figure>
<h3 id="2-命令行客户端支持的命令参数"><a href="#2-命令行客户端支持的命令参数" class="headerlink" title="2.命令行客户端支持的命令参数"></a>2.命令行客户端支持的命令参数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">[-checksum &lt;src&gt; ...]</span><br><span class="line">[-chgrp [-R] GROUP PATH...]</span><br><span class="line">[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">[-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">[-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">[-count [-q] &lt;path&gt; ...]</span><br><span class="line">[-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">[-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">[-du [-s] [-h] &lt;path&gt; ...]</span><br><span class="line">[-expunge]</span><br><span class="line">[-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">[-getfacl [-R] &lt;path&gt;]</span><br><span class="line">[-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">[-help [cmd ...]]</span><br><span class="line">[-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</span><br><span class="line">[-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">[-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">[-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">[-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</span><br><span class="line">[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span><br><span class="line">[-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">[-stat [format] &lt;path&gt; ...]</span><br><span class="line">[-tail [-f] &lt;file&gt;]</span><br><span class="line">[-test -[defsz] &lt;path&gt;]</span><br><span class="line">[-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">[-touchz &lt;path&gt; ...]</span><br><span class="line">[-usage [cmd ...]]</span><br></pre></td></tr></table></figure>
<h3 id="3-常用命令参数介绍"><a href="#3-常用命令参数介绍" class="headerlink" title="3.常用命令参数介绍"></a>3.常用命令参数介绍</h3><table>
<thead>
<tr>
<th>-help                功能：输出这个命令参数手册</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>-ls</strong>                     <strong>功能：显示目录信息</strong>   <em>示例： hadoop fs -ls hdfs://hadoop-server01:9000/</em>   <em>备注：这些参数中，所有的hdfs**路径都可以简写</em>   <em>–&gt;hadoop fs -ls /</em>     <em>等同于上一条命令的效果</em></td>
</tr>
<tr>
<td><strong>-mkdir</strong>                 <strong>功能：在hdfs**</strong>上创建目录*<em>   </em>示例：hadoop fs    -mkdir  -p    /aaa/bbb/cc/dd*</td>
</tr>
<tr>
<td><strong>-moveFromLocal</strong>               <strong>功能：从本地剪切粘贴到hdfs</strong>   <em>示例：hadoop  fs  -   moveFromLocal  /home/hadoop/a.txt  /aaa/bbb/cc/dd</em>   <strong>-moveToLocal</strong>                 <strong>功能：从hdfs**</strong>剪切粘贴到本地*<em>   </em>示例：hadoop  fs  -   moveToLocal   /aaa/bbb/cc/dd  /home/hadoop/a.txt*</td>
</tr>
<tr>
<td><strong>–appendToFile</strong>     <strong>功能：追加一个文件到已经存在的文件末尾</strong>   <em>示例：hadoop  fs  -appendToFile  ./hello.txt    hdfs://hadoop-server01:9000/hello.txt</em>   <em>可以简写为：</em>   <em>Hadoop  fs  -appendToFile  ./hello.txt    /hello.txt</em></td>
</tr>
<tr>
<td><strong>-cat</strong>     <strong>功能：显示文件内容</strong>       <em>示例：hadoop fs -cat    /hello.txt</em>       <strong>-tail</strong>                    <strong>功能：显示一个文件的末尾</strong>   <em>示例：hadoop  fs    -tail  /weblog/access_log.1</em>   <strong>-text</strong>                     <strong>功能：以字符形式打印一个文件的内容</strong>   <em>示例：hadoop  fs    -text  /weblog/access_log.1</em></td>
</tr>
<tr>
<td><strong>-chgrp</strong>    <strong>-chmod</strong>   <strong>-chown</strong>   <strong>功能：linux**</strong>文件系统中的用法一样，对文件所属权限*<em>   </em>示例：<em>   </em>hadoop  fs  -chmod    666  /hello.txt<em>   </em>hadoop  fs  -chown    someuser:somegrp   /hello.txt*</td>
</tr>
<tr>
<td><strong>-copyFromLocal</strong>       <strong>功能：从本地文件系统中拷贝文件到hdfs**</strong>路径去<strong>   <em>示例：hadoop  fs  -copyFromLocal  ./jdk.tar.gz  /aaa/</em>   </strong>-copyToLocal<strong>         </strong>功能：从hdfs<strong>**拷贝到本地</strong>   <em>示例：hadoop fs -copyToLocal   /aaa/jdk.tar.gz</em></td>
</tr>
<tr>
<td><strong>-cp</strong>                 <strong>功能：从hdfs**</strong>的一个路径拷贝hdfs<strong>**的另一个路径</strong>   <em>示例： hadoop  fs  -cp    /aaa/jdk.tar.gz    /bbb/jdk.tar.gz.2</em>       <strong>-mv</strong>                        <strong>功能：在hdfs**</strong>目录中移动文件*<em>   </em>示例： hadoop  fs  -mv  /aaa/jdk.tar.gz  /*</td>
</tr>
<tr>
<td><strong>-get</strong>                 <strong>功能：等同于copyToLocal**</strong>，就是从hdfs<strong>**下载文件到本地</strong>   示例：hadoop fs -get  /aaa/jdk.tar.gz   <strong>-</strong>            <strong>功能：合并下载多个文件</strong>   <em>示例：<strong>比</strong></em>getmerge<strong>    *如hdfs</strong>的目录 /aaa/*<em>下有多个文件:log.1, log.2,log.3,…</em>   hadoop   fs -getmerge /aaa/log.* ./log.sum</td>
</tr>
<tr>
<td><strong>-put</strong>                   <strong>功能：等同于copyFromLocal</strong>   <em>示例：hadoop  fs  -put  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2</em></td>
</tr>
<tr>
<td><strong>-rm</strong>                   <strong>功能：删除文件或文件夹</strong>   <em>示例：hadoop fs -rm   -r /aaa/bbb/</em>       <strong>-rmdir</strong>                    <strong>功能：删除空目录</strong>   <em>示例：hadoop  fs    -rmdir   /aaa/bbb/ccc</em></td>
</tr>
<tr>
<td><strong>-df</strong>                  <strong>功能：统计文件系统的可用空间信息</strong>   <em>示例：hadoop  fs  -df    -h  /</em>       <strong>-du</strong>    <strong>功能：统计文件夹的大小信息</strong>   <em>示例：</em>   *hadoop  fs  -du    -s  -h /aaa/**</td>
</tr>
<tr>
<td><strong>-count</strong>            <strong>功能：统计一个指定目录下的文件节点数量</strong>   <em>示例：hadoop fs -count /aaa/</em></td>
</tr>
<tr>
<td><strong>-setrep</strong>                   <strong>功能：设置hdfs**</strong>中文件的副本数量*<em>   </em>示例：hadoop fs -setrep 3 /aaa/jdk.tar.gz*</td>
</tr>
<tr>
<td>查看dfs集群工作状态的命令 hdfs dfsadmin -report</td>
</tr>
</tbody>
</table>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/20/3.hdfs-javaAPI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="严亮">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="代码块工作室">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/20/3.hdfs-javaAPI/" itemprop="url">
                  3.hdfs-javaAPI
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-09-20 10:18:32 / Modified: 11:56:24" itemprop="dateCreated datePublished" datetime="2018-09-20T10:18:32+08:00">2018-09-20</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/大数据/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h3 id="1-java操作hdfs环境搭建"><a href="#1-java操作hdfs环境搭建" class="headerlink" title="1.java操作hdfs环境搭建"></a>1.java操作hdfs环境搭建</h3><h4 id="1-1创建mvn项目添加依赖"><a href="#1-1创建mvn项目添加依赖" class="headerlink" title="1.1创建mvn项目添加依赖"></a>1.1创建mvn项目添加依赖</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;2.6.4&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;2.6.4&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;2.6.4&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;jdk.tools&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;jdk.tools&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;1.6&lt;/version&gt;</span><br><span class="line">	&lt;scope&gt;system&lt;/scope&gt;</span><br><span class="line">	&lt;systemPath&gt;$&#123;JAVA_HOME&#125;/lib/tools.jar&lt;/systemPath&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h4 id="1-2测试"><a href="#1-2测试" class="headerlink" title="1.2测试"></a>1.2测试</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取/路径下面的所有文件</span></span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">configuration.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://min1:9000"</span>);</span><br><span class="line">FileSystem fs = FileSystem.get(configuration);</span><br><span class="line">RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line"><span class="keyword">while</span>(listFiles.hasNext()) &#123;</span><br><span class="line">	LocatedFileStatus fileStatus = listFiles.next();</span><br><span class="line">	String name = fileStatus.getPath().getName(); <span class="comment">//打印文件名</span></span><br><span class="line">	System.out.println(name);</span><br><span class="line">&#125;</span><br><span class="line">fs.close();</span><br></pre></td></tr></table></figure>
<h4 id="1-3结果"><a href="#1-3结果" class="headerlink" title="1.3结果"></a>1.3结果</h4><p>每个人的结果不同。本人的下面有三个文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">linux.log</span><br><span class="line">windows.log</span><br><span class="line">profile</span><br></pre></td></tr></table></figure>
<h3 id="2-hdfs客户端权限身份伪造的问题"><a href="#2-hdfs客户端权限身份伪造的问题" class="headerlink" title="2.hdfs客户端权限身份伪造的问题"></a>2.hdfs客户端权限身份伪造的问题</h3><p>为什么需要权限身份伪造？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 执行下面代码，需求是把本地文件上传到hdfs的/路径下</span><br><span class="line">fs.copyFromLocalFile(new Path(&quot;d://a.txt&quot;), new Path(&quot;/&quot;));</span><br><span class="line">fs.close();</span><br></pre></td></tr></table></figure>
<p>不幸的是报错了，说Administrator这个用户没有/的权限，/路径的用户是root组是supergroup，所有我们现在需要去伪造用户成root.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.security.AccessControlException: Permission denied: user=Administrator, access=WRITE, inode=&quot;/&quot;:root:supergroup:drwxr-xr-x</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)</span><br></pre></td></tr></table></figure>
<p>处理方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">方式一：</span><br><span class="line">   		Configuration configuration = new Configuration();</span><br><span class="line">		configuration.set(&quot;fs.defaultFS&quot;, &quot;hdfs://min1:9000&quot;);</span><br><span class="line">		try &#123;</span><br><span class="line">			System.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;root&quot;);</span><br><span class="line">			fs = FileSystem.get(configuration);</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">		注意：System.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;root&quot;);只能放在fs = FileSystem.get(configuration);前面，不然你就彩蛋了。</span><br><span class="line">方式二：</span><br><span class="line">	Configuration configuration = new Configuration();</span><br><span class="line">	fs = FileSystem.get(new URI(&quot;hdfs://min1:9000&quot;), configuration, &quot;root&quot;);</span><br><span class="line"></span><br><span class="line">方式三：百度一下</span><br></pre></td></tr></table></figure>
<h3 id="3-windows平台下开发hadoop需要注意的细节"><a href="#3-windows平台下开发hadoop需要注意的细节" class="headerlink" title="3.windows平台下开发hadoop需要注意的细节"></a>3.windows平台下开发hadoop需要注意的细节</h3><p>运行下面代码把hdfs中文件拷贝到windows下。下载功能</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fs.copyToLocalFile(new Path(&quot;/a.txt&quot;), new Path(&quot;d:/&quot;));</span><br><span class="line">fs.close();</span><br></pre></td></tr></table></figure>
<p>我去又报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.NullPointerException</span><br><span class="line">	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)</span><br><span class="line">	at org.apache.hadoop.util.Shell.runCommand(Shell.java:482)</span><br><span class="line">	at org.apache.hadoop.util.Shell.run(Shell.java:455)</span><br><span class="line">	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)</span><br><span class="line">	at org.apache.hadoop.util.Shell.execCommand(Shell.java:808)</span><br><span class="line">	at org.apache.hadoop.util.Shell.execCommand(Shell.java:791)</span><br><span class="line">	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:659)</span><br><span class="line">	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:490)</span><br><span class="line">	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:462)</span><br><span class="line">	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:428)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:908)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:889)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:786)</span><br><span class="line">	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:365)</span><br><span class="line">	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:338)</span><br><span class="line">	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1970)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1939)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1915)</span><br><span class="line">	at cn.mytest.hdfs.TestHDFS.main(TestHDFS.java:30)</span><br></pre></td></tr></table></figure>
<p>原因：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop要与windows打交道，需要通过和windows的相关的类库进行交互操作文件。而本地不存在hadoop交互的类库。</span><br></pre></td></tr></table></figure>
<p>建议：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">方式一：</span><br><span class="line">建议在linux下进行hadoop应用的开发，不会存在兼容性问题。如在window上做客户端应用开发，需要设置以下环境：</span><br><span class="line">A、用给的windows平台下编译的hadoop安装包解压一份到windows的任意一个目录下</span><br><span class="line">B、在window系统中配置HADOOP_HOME指向你解压的安装包目录</span><br><span class="line">C、在windows系统的path变量中加入HADOOP_HOME的bin目录</span><br><span class="line"></span><br><span class="line">方式二:</span><br><span class="line">采用java自己的io直接写入文件</span><br><span class="line">fs.copyToLocalFile(false, new Path(&quot;/a.txt&quot;), new Path(&quot;d:/&quot;), true);</span><br></pre></td></tr></table></figure>
<h3 id="4-hdfs客户端文件上传"><a href="#4-hdfs客户端文件上传" class="headerlink" title="4.hdfs客户端文件上传"></a>4.hdfs客户端文件上传</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Before</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 构造一个配置参数对象，设置一个参数：我们要访问的hdfs的URI</span></span><br><span class="line">		<span class="comment">// 从而FileSystem.get()方法就知道应该是去构造一个访问hdfs文件系统的客户端，以及hdfs的访问地址</span></span><br><span class="line">		<span class="comment">// new Configuration();的时候，它就会去加载jar包中的hdfs-default.xml</span></span><br><span class="line">		<span class="comment">// 然后再加载classpath下的hdfs-site.xml</span></span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		<span class="comment">// conf.set("fs.defaultFS", "hdfs://mini1:9000");</span></span><br><span class="line">		<span class="comment">//参数优先级： 1、客户端代码中设置的值 2、classpath下的用户自定义配置文件 3、然后是服务器的默认配置</span></span><br><span class="line">		<span class="comment">/*conf.set("dfs.replication", "2");</span></span><br><span class="line"><span class="comment">		conf.set("dfs.block.size", "64m");*/</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">// 获取一个hdfs的访问客户端，根据参数，这个实例应该是DistributedFileSystem的实例</span></span><br><span class="line">		<span class="comment">// fs = FileSystem.get(conf);</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">// 如果这样去获取，那conf里面就可以不要配"fs.defaultFS"参数，而且，这个客户端的身份标识已经是root用户</span></span><br><span class="line">		fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://mini1:9000"</span>), conf, <span class="string">"root"</span>);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">方式一：</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testAddFileToHdfs</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		Path src = <span class="keyword">new</span> Path(<span class="string">"d://a.txt"</span>);</span><br><span class="line">		Path dst = <span class="keyword">new</span> Path(<span class="string">"/"</span>);</span><br><span class="line">		fs.copyFromLocalFile(src, dst);</span><br><span class="line"></span><br><span class="line">		fs.close();</span><br><span class="line">	&#125;</span><br><span class="line">方式二流:</span><br><span class="line">	FileInputStream in = <span class="keyword">new</span> FileInputStream(<span class="string">"d://a.txt"</span>);</span><br><span class="line">	Path path = <span class="keyword">new</span> Path(<span class="string">"/aa.txt"</span>);</span><br><span class="line">	FSDataOutputStream out = fs.create(path);</span><br><span class="line">	IOUtils.copy(in, out);</span><br><span class="line">	fs.close();</span><br></pre></td></tr></table></figure>
<h3 id="5-hdfs客户端文件下载"><a href="#5-hdfs客户端文件下载" class="headerlink" title="5.hdfs客户端文件下载"></a>5.hdfs客户端文件下载</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">方式一:</span><br><span class="line">    fs.copyToLocalFile(<span class="keyword">false</span>, <span class="keyword">new</span> Path(<span class="string">"/a.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"d:/"</span>), <span class="keyword">true</span>);</span><br><span class="line">    fs.close();</span><br><span class="line">方式二流：</span><br><span class="line">    FSDataInputStream in = fs.open(<span class="keyword">new</span> Path(<span class="string">"/a.txt"</span>));</span><br><span class="line">    FileOutputStream out = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"d:/a.txt"</span>));</span><br><span class="line">    IOUtils.copy(in, out);</span><br><span class="line">    fs.close();</span><br></pre></td></tr></table></figure>
<h3 id="6-hdfs客户端目录操作、查看文件夹以及文件信息"><a href="#6-hdfs客户端目录操作、查看文件夹以及文件信息" class="headerlink" title="6.hdfs客户端目录操作、查看文件夹以及文件信息"></a>6.hdfs客户端目录操作、查看文件夹以及文件信息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//查看目录信息，只显示文件</span></span><br><span class="line">RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line"><span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">    LocatedFileStatus fileStatus = listFiles.next();</span><br><span class="line">    System.out.println(fileStatus.getPath().getName());</span><br><span class="line">    System.out.println(fileStatus.getBlockSize());</span><br><span class="line">    System.out.println(fileStatus.getPermission());</span><br><span class="line">    System.out.println(fileStatus.getLen());</span><br><span class="line">    BlockLocation[] blockLocations = fileStatus.getBlockLocations();</span><br><span class="line">    <span class="keyword">for</span> (BlockLocation bl : blockLocations) &#123;</span><br><span class="line">        System.out.println(<span class="string">"block-length:"</span> + bl.getLength() + <span class="string">"--"</span> + <span class="string">"block-offset:"</span> + bl.getOffset());</span><br><span class="line">        String[] hosts = bl.getHosts();</span><br><span class="line">        <span class="keyword">for</span> (String host : hosts) &#123;</span><br><span class="line">            System.out.println(host);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="string">"--------------分割线--------------"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 查看文件及文件夹信息</span></span><br><span class="line">FileStatus[] listStatus = fs.listStatus(<span class="keyword">new</span> Path(<span class="string">"/"</span>));</span><br><span class="line">String flag = <span class="string">""</span>;</span><br><span class="line"><span class="keyword">for</span> (FileStatus fstatus : listStatus) &#123;</span><br><span class="line">    <span class="keyword">if</span> (fstatus.isFile()) &#123;</span><br><span class="line">        flag = <span class="string">"文件"</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        flag = <span class="string">"文件夹"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(flag + fstatus.getPath().getName());</span><br><span class="line">    System.out.println(fstatus.getPermission());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// hdfs支持随机定位进行文件读取，而且可以方便地读取指定长度 用于上层分布式运算框架并发处理数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 先获取一个文件的输入流----针对hdfs上的</span></span><br><span class="line">FSDataInputStream in = fs.open(<span class="keyword">new</span> Path(<span class="string">"/a.txt"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以将流的起始偏移量进行自定义</span></span><br><span class="line">in.seek(<span class="number">22</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 再构造一个文件的输出流----针对本地的</span></span><br><span class="line">FileOutputStream out = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"d:/a.txt"</span>));</span><br><span class="line">org.apache.hadoop.io.IOUtils.copyBytes(in, out, <span class="number">19L</span>, <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/19/1.centos7上安装hadoop2.X集群/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="严亮">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="代码块工作室">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/19/1.centos7上安装hadoop2.X集群/" itemprop="url">
                  1.centos7上安装hadoop2.X集群
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-09-19 17:49:34" itemprop="dateCreated datePublished" datetime="2018-09-19T17:49:34+08:00">2018-09-19</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-09-20 11:54:52" itemprop="dateModified" datetime="2018-09-20T11:54:52+08:00">2018-09-20</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/大数据/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​1.0先将虚拟机的网络模式选为NAT</p>
<pre><code>1.1修改主机名
    vi /etc/hostname

1.2修改IP
        vi /etc/sysconfig/network-scripts/ifcfg-ens33

        TYPE=Ethernet
        PROXY_METHOD=none
        BROWSER_ONLY=no
        BOOTPROTO=static   ###
        DEFROUTE=yes
        IPV4_FAILURE_FATAL=no
        IPV6INIT=yes
        IPV6_AUTOCONF=yes
        IPV6_DEFROUTE=yes
        IPV6_FAILURE_FATAL=no
        IPV6_ADDR_GEN_MODE=stable-privacy
        NAME=ens33
        UUID=43e8ca15-c8b3-41ae-b99c-e9587c763cad
        DEVICE=ens33
        GATEWAY=192.168.100.2  ###
        NETMASK=255.255.255.0 ###
        IPADDR=192.168.100.10  ###
        DNS1=114.114.114.114 ###
        DNS2=8.8.8.8   ###
        DNS3=192.168.100.1  ###
        ONBOOT=yes         ###
</code></pre><p>​<br>​    1.3修改主机名和IP的映射关系<br>​        vim /etc/hosts<br>​<br>​        192.168.100.10 min1<br>​        192.168.100.11 min2<br>​        192.168.100.12 min3<br>​        192.168.100.13 min4<br>​<br>​    1.4关闭防火墙<br>​        systemctl stop firewalld<br>​        systemctl disable firewalld<br>​    1.5重启Linux<br>​        reboot</p>
<p>2.安装JDK</p>
<pre><code>2.1上传alt+p 后出现sftp窗口，然后put d:\xxx\yy\ll\jdk-8u181-linux-x64.tar.gz
2.2解压jdk
        #解压
        tar -zxvf jdk-8u181-linux-x64.tar.gz

2.3将java添加到环境变量中
    vim /etc/profile
    #在文件最后添加
    export JAVA_HOME=/opt/jdk1.8
    export PATH=$PATH:$JAVA_HOME/bin

    #刷新配置
    source /etc/profile
</code></pre><p>3.安装hadoop2.6.4<br>​    先上传hadoop的安装包到服务器上去/opt<br>​    注意：hadoop2.x的配置文件$HADOOP_HOME/etc/hadoop<br>​    伪分布式需要修改5个配置文件<br>3.1配置hadoop</p>
<pre><code>第一个：hadoop-env.sh
        vim hadoop-env.sh
        #第25行
        export JAVA_HOME=/opt/jdk1.8

第二个：core-site.xml
&lt;!-- 指定HADOOP所使用的文件系统schema（URI），HDFS的老大（NameNode）的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://min1:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/hadoop-2.6.4/tmp&lt;/value&gt;
&lt;/property&gt;

第三个：hdfs-site.xml   
    &lt;!-- 指定HDFS副本的数量 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;dfs.secondary.http.address&lt;/name&gt;
        &lt;value&gt;192.168.1.152:50090&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--自己选择添加----&gt;
     &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;/home/hadoop/data/name,/path2/,/path3/,nfs://&lt;/value&gt;
    &lt;/property&gt;
    &lt;!---namenode配置多个目录和datanode配置多个目录，有什么区别？----&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;/home/hadoop/data/data,/path2/&lt;/value&gt;
    &lt;/property&gt;

第四个：mapred-site.xml (mv mapred-site.xml.template mapred-site.xml)
    mv mapred-site.xml.template mapred-site.xml
    vim mapred-site.xml
    &lt;!-- 指定mr运行在yarn上 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;

第五个：yarn-site.xml
    &lt;!-- 指定YARN的老大（ResourceManager）的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;min1&lt;/value&gt;
&lt;/property&gt;
    &lt;!-- reducer获取数据的方式 --&gt;
&lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
 &lt;/property&gt;




3.2将hadoop添加到环境变量

vim /etc/proflie
    export JAVA_HOME=/opt/jdk1.8
    export HADOOP_HOME=/opt/hadoop-2.6.4
    export PATH=${PATH}:${JAVA_HOME}/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

source /etc/profile

3.3格式化namenode（是对namenode进行初始化）
    hdfs namenode -format (hadoop namenode -format)

3.4启动hadoop
    先启动HDFS
    sbin/start-dfs.sh

    再启动YARN
    sbin/start-yarn.sh

3.5验证是否启动成功
    使用jps命令验证
    27408 NameNode
    28218 Jps
    27643 SecondaryNameNode
    28066 NodeManager
    27803 ResourceManager
    27512 DataNode

    http://192.168.100.10:50070 （HDFS管理界面）
    http://192.168.100.10:8088 （MR管理界面）
</code></pre><p>4.配置ssh免登陆​    </p>
<pre><code>#生成ssh免登陆密钥
#进入到我的home目录
cd ~/.ssh
ssh-keygen -t rsa （四个回车）
执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）
将公钥拷贝到要免密登陆的目标机器上
ssh-copy-id localhost
</code></pre><ol start="5">
<li>启动命令​    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">单一的启动方式</span><br><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line">hadoop-daemon.sh start datanode</span><br><span class="line">hadoop-daemon.sh start secondarynamenode</span><br><span class="line">批量启动</span><br><span class="line">	先要去修改 vi /opt/hadoop-2.6.4/etc/hadoop/slaves</span><br><span class="line">	把需要启动的主机添加到文件中</span><br><span class="line">	min1</span><br><span class="line">    min2</span><br><span class="line">    min3</span><br><span class="line">start-dfs.sh</span><br><span class="line"></span><br><span class="line">验证</span><br><span class="line">http://192.168.100.10:50070</span><br><span class="line"></span><br><span class="line">hdfs dfs -put 本地文件路径 hdfs的文件路径</span><br><span class="line">hdfs dfs -put /etc/profile /</span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/16/鸡汤/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="严亮">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="代码块工作室">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/16/鸡汤/" itemprop="url">
                  什么是鸡汤？
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-16 09:33:32" itemprop="dateCreated datePublished" datetime="2018-08-16T09:33:32+08:00">2018-08-16</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-08-17 09:32:02" itemprop="dateModified" datetime="2018-08-17T09:32:02+08:00">2018-08-17</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/鸡汤/" itemprop="url" rel="index"><span itemprop="name">鸡汤</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>学习分什么高低贵贱，从零好好开始。 2018年8月16日10:54:09<br>明确的说今天我们还不足够的优秀，那就多读书。    2018年8月17日09:31:36 </p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">严亮</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">严亮</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Muse</a> v6.4.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script>



  



  










  





  

  

  

  

  
  

  

  

  

  

  

</body>
</html>
